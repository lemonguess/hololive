import requests
import json


def bocha_search(query: str, api_key: str=None, mode: str = "web", max_results: int = 5) -> str:
    """
    è°ƒç”¨åšæŸ¥APIè¿›è¡Œæœç´¢
    :param query: æœç´¢å…³é”®è¯
    :param api_key: APIå¯†é’¥ï¼ˆæ ¼å¼ä¸º`sk-xxxxxx`ï¼‰
    :param mode: æœç´¢æ¨¡å¼ï¼Œå¯é€‰ `web`ï¼ˆç½‘é¡µæœç´¢ï¼‰æˆ– `ai`ï¼ˆå¤šæ¨¡æ€æœç´¢ï¼‰
    :param max_results: æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆ1-50ï¼‰
    :return: æ ¼å¼åŒ–åçš„æœç´¢ç»“æœå­—ç¬¦ä¸²
    """
    # é…ç½®APIç«¯ç‚¹
    url = "https://api.bochaai.com/v1/web-search" if mode == "web" else "https://api.bochaai.com/v1/ai-search"
    api_key = "sk-9a538f2c30534de1b20895782d39a987"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "query": query,
        "count": max_results,
        "freshness": "noLimit",
        "answer": False,  # AIæ¨¡å¼æ˜¯å¦å¯ç”¨å¤§æ¨¡å‹æ€»ç»“
        "stream": False  # æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯
        data = response.json()

        # è§£æå¤šæ¨¡æ€ç»“æœ
        if mode == "ai":
            return _parse_ai_results(data)
        else:
            return _parse_web_results(data)

    except requests.exceptions.RequestException as e:
        return f"è¯·æ±‚å¤±è´¥: {str(e)}"
    except KeyError:
        return "å“åº”æ ¼å¼è§£æé”™è¯¯"


def _parse_web_results(data: dict) -> str:
    """è§£ææ™®é€šç½‘é¡µæœç´¢ç»“æœ"""
    results = data.get("data", {}).get("webPages", {}).get("value", [])
    return [{"title": r["name"], "href": r["url"], "body": r["snippet"]} for r in results]
    # return "\n\n".join([
    #     f"Title: {item['name']}\nURL: {item['url']}\nSnippet: {item['snippet']}"
    #     for item in results[:5]
    # ])


def _parse_ai_results(data: dict) -> str:
    """è§£æAIå¤šæ¨¡æ€ç»“æœï¼ˆå¤©æ°”/ç™¾ç§‘/åŒ»ç–—ç­‰å¡ç‰‡ï¼‰"""
    output = []
    # æå–æ–‡å­—ç»“æœ
    web_pages = data.get("data", {}).get("webPages", {}).get("value", [])
    for item in web_pages[:3]:
        output.append(f"ğŸ“ æ–‡å­—ç»“æœ:\næ ‡é¢˜: {item['name']}\né“¾æ¥: {item['url']}\næ‘˜è¦: {item['snippet']}")

    # æå–å‚ç›´å¡ç‰‡ï¼ˆå¦‚å¤©æ°”/ç™¾ç§‘ï¼‰
    content_type = data.get("data", {}).get("content_type", "")
    if content_type == "weather":
        weather_info = data["data"]["weatherCard"]
        output.append(
            f"ğŸŒ¤ï¸ å¤©æ°”å¡ç‰‡:\nåŸå¸‚: {weather_info['city']}\næ¸©åº¦: {weather_info['temp']}â„ƒ\nå¤©æ°”: {weather_info['condition']}")

    return "\n\n".join(output)